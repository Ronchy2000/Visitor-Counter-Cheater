#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¥¿ç”µæ•™å¸ˆä¸»é¡µè®¿é—®é‡åˆ·æ–°å·¥å…· (é«˜æ•ˆç‰ˆ)

åŸç†åˆ†æï¼š
é¡µé¢åŠ è½½æ—¶ä¼šè°ƒç”¨ _tsites_updateVisit_() å‡½æ•°
è¯¥å‡½æ•°ä¼šå‘é€ä¸€ä¸ªå›¾ç‰‡è¯·æ±‚åˆ°ï¼š
/system/resource/tsites/click.jsp?lc={path}&hosts={host}&ac=updateVisit&vp=&os={OS}&bs={browser}

æˆ‘ä»¬ç›´æ¥æ¨¡æ‹Ÿè¿™ä¸ªè¯·æ±‚å³å¯ï¼
"""
import urllib.request
import urllib.parse
import time
import random
import csv
import os
from datetime import datetime, timezone

# ============= é…ç½®åŒºåŸŸ =================
CONFIG = {
    "URL": "https://faculty.xidian.edu.cn/DANIEL/zh_CN/index.htm",
    "MAX_VISITS": 100,          # æœ€å¤§è®¿é—®æ¬¡æ•°
    "INTERVAL_MEAN": 1.0,       # å¹³å‡é—´éš”ï¼ˆç§’ï¼‰
    "INTERVAL_MIN": 0.5,        # æœ€å°é—´éš”ï¼ˆç§’ï¼‰
    "CSV_FILE": "visits_log_xidian.csv",
    "TIMEOUT": 10,
}
# ========================================

# æ“ä½œç³»ç»Ÿåˆ—è¡¨
OS_LIST = [
    "Win10 64ä½",
    "Win10 32ä½",
    "Win7 64ä½",
    "Win7 32ä½",
    "Mac 64ä½",
    "Linux 64ä½",
    "Android 64ä½",
]

# æµè§ˆå™¨åˆ—è¡¨
BROWSER_LIST = [
    "Chrome",
    "Firefox",
    "Microsoft IE",
    "Safari",
    "Edge",
]

# User-Agent åˆ—è¡¨
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
]

def get_log_file_path():
    """è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    logs_dir = os.path.join(script_dir, "logs")
    if not os.path.exists(logs_dir):
        os.makedirs(logs_dir)
    return os.path.join(logs_dir, CONFIG["CSV_FILE"])

def now_iso():
    """è¿”å›å½“å‰ UTC æ—¶é—´"""
    return datetime.now(timezone.utc).isoformat()

def get_interval():
    """ç”Ÿæˆéšæœºé—´éš”"""
    interval = random.expovariate(1.0 / CONFIG["INTERVAL_MEAN"])
    return max(CONFIG["INTERVAL_MIN"], interval)

def write_csv_header(csvfile):
    """å†™å…¥ CSV æ–‡ä»¶å¤´"""
    file_exists = os.path.exists(csvfile) and os.path.getsize(csvfile) > 0
    if not file_exists:
        with open(csvfile, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([
                "timestamp_utc",
                "visit_number",
                "url",
                "user_agent",
                "os",
                "browser",
                "status",
                "response_time_ms",
                "note"
            ])

def log_visit(visit_num, url, user_agent, os, browser, status, response_time, note=""):
    """è®°å½•è®¿é—®æ—¥å¿—"""
    log_file = get_log_file_path()
    with open(log_file, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([
            now_iso(),
            visit_num,
            url,
            user_agent,
            os,
            browser,
            status,
            response_time,
            note
        ])

def update_visit(target_url, user_agent, os, browser):
    """
    æ¨¡æ‹Ÿè®¿é—®é‡æ›´æ–°è¯·æ±‚
    
    å…³é”®è¯·æ±‚ï¼š
    /system/resource/tsites/click.jsp?lc={pathname}&hosts={host}&ac=updateVisit&vp=&os={OS}&bs={browser}
    """
    try:
        # è§£æç›®æ ‡ URL
        from urllib.parse import urlparse
        parsed = urlparse(target_url)
        pathname = parsed.path
        hosts = parsed.netloc
        
        # æ„é€ è®¡æ•°å™¨è¯·æ±‚çš„ URL
        base_url = f"{parsed.scheme}://{parsed.netloc}"
        click_url = base_url + "/system/resource/tsites/click.jsp"
        
        # æ„é€ å‚æ•°
        params = {
            "lc": pathname,
            "hosts": hosts,
            "ac": "updateVisit",
            "vp": "",  # visite_record_collect_paramsï¼Œé€šå¸¸ä¸ºç©º
            "os": os,
            "bs": browser
        }
        
        # ç¼–ç å‚æ•°
        query_string = urllib.parse.urlencode(params)
        full_url = f"{click_url}?{query_string}"
        
        # æ„é€ è¯·æ±‚å¤´
        headers = {
            "User-Agent": user_agent,
            "Referer": target_url,
            "Accept": "image/webp,image/apng,image/*,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Connection": "keep-alive",
        }
        
        # å‘é€è¯·æ±‚
        req = urllib.request.Request(full_url, headers=headers)
        start_time = time.time()
        
        with urllib.request.urlopen(req, timeout=CONFIG["TIMEOUT"]) as response:
            data = response.read()
            response_time = int((time.time() - start_time) * 1000)
        
        return "SUCCESS", response_time, ""
        
    except urllib.error.HTTPError as e:
        return "HTTP_ERROR", 0, f"HTTP {e.code}: {e.reason}"
    except urllib.error.URLError as e:
        return "URL_ERROR", 0, str(e.reason)
    except Exception as e:
        return "EXCEPTION", 0, str(e)

def main():
    """ä¸»å‡½æ•°"""
    url = CONFIG["URL"]
    max_visits = CONFIG["MAX_VISITS"]
    log_file = get_log_file_path()
    
    print("ğŸ¯ è¥¿ç”µæ•™å¸ˆä¸»é¡µè®¿é—®é‡åˆ·æ–°å·¥å…·")
    print("=" * 70)
    print(f"ğŸ“ ç›®æ ‡ç½‘å€: {url}")
    print(f"ğŸ”¢ æœ€å¤§è®¿é—®æ¬¡æ•°: {max_visits if max_visits > 0 else 'æ— é™'}")
    print(f"â±ï¸  å¹³å‡é—´éš”: {CONFIG['INTERVAL_MEAN']} ç§’")
    print(f"ğŸ’¾ æ—¥å¿—æ–‡ä»¶: {log_file}")
    print(f"âš¡ åŸç†: ç›´æ¥æ¨¡æ‹Ÿ click.jsp è¯·æ±‚")
    print("=" * 70)
    
    write_csv_header(log_file)
    
    visit_count = 0
    success_count = 0
    total_response_time = 0
    
    try:
        while True:
            if max_visits > 0 and visit_count >= max_visits:
                print(f"\nâœ… å·²å®Œæˆ {visit_count} æ¬¡è®¿é—®")
                break
            
            visit_count += 1
            
            # éšæœºé€‰æ‹©å‚æ•°
            user_agent = random.choice(USER_AGENTS)
            os = random.choice(OS_LIST)
            browser = random.choice(BROWSER_LIST)
            
            print(f"\n[è®¿é—® #{visit_count}]")
            print(f"  ğŸ–¥ï¸  OS: {os}")
            print(f"  ğŸŒ Browser: {browser}")
            print(f"  ğŸ“± UA: {user_agent[:60]}...")
            
            # å‘é€è¯·æ±‚
            status, response_time, note = update_visit(url, user_agent, os, browser)
            
            if status == "SUCCESS":
                success_count += 1
                total_response_time += response_time
                print(f"  âœ… è®¿é—®æˆåŠŸ ({response_time}ms)")
            else:
                print(f"  âŒ {status}: {note}")
            
            # è®°å½•æ—¥å¿—
            log_visit(visit_count, url, user_agent, os, browser, status, response_time, note)
            
            # ç­‰å¾…
            if max_visits == 0 or visit_count < max_visits:
                interval = get_interval()
                print(f"  â³ ç­‰å¾… {interval:.1f} ç§’...")
                time.sleep(interval)
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    
    finally:
        print(f"\n{'='*70}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
        print(f"{'='*70}")
        print(f"æ€»è®¿é—®æ¬¡æ•°: {visit_count}")
        print(f"æˆåŠŸæ¬¡æ•°: {success_count}")
        if visit_count > 0:
            print(f"æˆåŠŸç‡: {success_count/visit_count*100:.1f}%")
        if success_count > 0:
            print(f"å¹³å‡å“åº”æ—¶é—´: {total_response_time/success_count:.0f}ms")
        print(f"ğŸ’¾ æ—¥å¿—: {log_file}")

if __name__ == "__main__":
    main()
